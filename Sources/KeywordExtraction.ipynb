{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KeywordExtraction.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOSxM+qt2QVqeYX0/dYrHAf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/huynhhoc/AI-VLU/blob/main/Sources/KeywordExtraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z55_-u5SpQFJ"
      },
      "source": [
        "Extracting Keywords with TF-IDF and Python’s Scikit-Learn\n",
        "TF-IDF can be used for a wide range of tasks including:\n",
        "1. text classification\n",
        "2. clustering / topic-modeling\n",
        "3. search\n",
        "4. keyword extraction and a whole lot more\n",
        "Source: https://kavita-ganesan.com/extracting-keywords-from-text-tfidf/#.YRuOZ4gzbIU"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOOjntp3ystd"
      },
      "source": [
        "**Dataset**\n",
        "We will be using two files, one file, stackoverflow-data-idf.json has 20,000 posts and is used to compute the Inverse Document Frequency (IDF) and another file, stackoverflow-test.json has 500 posts and we would use that as a test set for us to extract keywords from. This dataset is based on the publicly available stack overflow dump from Google’s Big Query."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EEB2ASv3pSoB",
        "outputId": "75c9ac1d-3b7d-40c9-ca82-1adb4223054d"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# read json into a dataframe\n",
        "df_idf=pd.read_json(\"https://raw.githubusercontent.com/kavgan/nlp-in-practice/master/tf-idf/data/stackoverflow-data-idf.json\",lines=True)\n",
        "\n",
        "# print schema\n",
        "print(\"Schema:\\n\\n\",df_idf.dtypes)\n",
        "print(\"Number of questions,columns=\",df_idf.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Schema:\n",
            "\n",
            " id                            int64\n",
            "title                        object\n",
            "body                         object\n",
            "answer_count                  int64\n",
            "comment_count                 int64\n",
            "creation_date                object\n",
            "last_activity_date           object\n",
            "last_editor_display_name     object\n",
            "owner_display_name           object\n",
            "owner_user_id               float64\n",
            "post_type_id                  int64\n",
            "score                         int64\n",
            "tags                         object\n",
            "view_count                    int64\n",
            "accepted_answer_id          float64\n",
            "favorite_count              float64\n",
            "last_edit_date               object\n",
            "last_editor_user_id         float64\n",
            "community_owned_date         object\n",
            "dtype: object\n",
            "Number of questions,columns= (20000, 19)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsaFEbVt3pzz",
        "outputId": "84b8e2b5-bcc9-4ec5-b3ce-d2f70322f552",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "import re\n",
        "def pre_process(text):\n",
        "    \n",
        "    # lowercase\n",
        "    text=text.lower()\n",
        "    \n",
        "    #remove tags\n",
        "    text=re.sub(\"</?.*?>\",\" <> \",text)\n",
        "    \n",
        "    # remove special characters and digits\n",
        "    text=re.sub(\"(\\\\d|\\\\W)+\",\" \",text)\n",
        "    \n",
        "    return text\n",
        "\n",
        "df_idf['text'] = df_idf['title'] + df_idf['body']\n",
        "df_idf['text'] = df_idf['text'].apply(lambda x:pre_process(x))\n",
        "\n",
        "#show the first 'text'\n",
        "df_idf['text'][2]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'gradle command line i m trying to run a shell script with gradle i currently have something like this def test project tasks create test exec commandline bash c bash c my file dir script sh the problem is that i cannot run this script because i have spaces in my dir name i have tried everything e g commandline bash c bash c my file dir script sh tokenize commandline bash c bash c my file dir script sh commandline bash c new stringbuilder append bash append c my file dir script sh commandline bash c bash c my file dir script sh file dir file c my file dir script sh commandline bash c bash dir getabsolutepath im using windows bit and if i use a path without spaces the script runs perfectly therefore the only issue as i can see is how gradle handles spaces '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPsY-dDF4f3Z"
      },
      "source": [
        "# Creating the IDF\n",
        "\n",
        "CountVectorizer to create a vocabulary and generate word counts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTdK8JQzpRpD"
      },
      "source": [
        ""
      ]
    }
  ]
}