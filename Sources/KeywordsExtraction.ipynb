{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KeywordExtraction.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNTFRZG3Zjo5MkXumSNNCHh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/huynhhoc/AI-VLU/blob/main/Sources/KeywordsExtraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z55_-u5SpQFJ"
      },
      "source": [
        "Extracting Keywords with TF-IDF and Python’s Scikit-Learn\n",
        "TF-IDF can be used for a wide range of tasks including:\n",
        "1. text classification\n",
        "2. clustering / topic-modeling\n",
        "3. search\n",
        "4. keyword extraction and a whole lot more\n",
        "Source: https://kavita-ganesan.com/extracting-keywords-from-text-tfidf/#.YRuOZ4gzbIU"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOOjntp3ystd"
      },
      "source": [
        "**Dataset**\n",
        "We will be using two files, one file, stackoverflow-data-idf.json has 20,000 posts and is used to compute the Inverse Document Frequency (IDF) and another file, stackoverflow-test.json has 500 posts and we would use that as a test set for us to extract keywords from. This dataset is based on the publicly available stack overflow dump from Google’s Big Query."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EEB2ASv3pSoB",
        "outputId": "75c9ac1d-3b7d-40c9-ca82-1adb4223054d"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# read json into a dataframe\n",
        "df_idf=pd.read_json(\"https://raw.githubusercontent.com/kavgan/nlp-in-practice/master/tf-idf/data/stackoverflow-data-idf.json\",lines=True)\n",
        "\n",
        "# print schema\n",
        "print(\"Schema:\\n\\n\",df_idf.dtypes)\n",
        "print(\"Number of questions,columns=\",df_idf.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Schema:\n",
            "\n",
            " id                            int64\n",
            "title                        object\n",
            "body                         object\n",
            "answer_count                  int64\n",
            "comment_count                 int64\n",
            "creation_date                object\n",
            "last_activity_date           object\n",
            "last_editor_display_name     object\n",
            "owner_display_name           object\n",
            "owner_user_id               float64\n",
            "post_type_id                  int64\n",
            "score                         int64\n",
            "tags                         object\n",
            "view_count                    int64\n",
            "accepted_answer_id          float64\n",
            "favorite_count              float64\n",
            "last_edit_date               object\n",
            "last_editor_user_id         float64\n",
            "community_owned_date         object\n",
            "dtype: object\n",
            "Number of questions,columns= (20000, 19)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "tsaFEbVt3pzz",
        "outputId": "84b8e2b5-bcc9-4ec5-b3ce-d2f70322f552"
      },
      "source": [
        "import re\n",
        "def pre_process(text):\n",
        "    \n",
        "    # lowercase\n",
        "    text=text.lower()\n",
        "    \n",
        "    #remove tags\n",
        "    text=re.sub(\"</?.*?>\",\" <> \",text)\n",
        "    \n",
        "    # remove special characters and digits\n",
        "    text=re.sub(\"(\\\\d|\\\\W)+\",\" \",text)\n",
        "    \n",
        "    return text\n",
        "\n",
        "df_idf['text'] = df_idf['title'] + df_idf['body']\n",
        "df_idf['text'] = df_idf['text'].apply(lambda x:pre_process(x))\n",
        "\n",
        "#show the first 'text'\n",
        "df_idf['text'][2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'gradle command line i m trying to run a shell script with gradle i currently have something like this def test project tasks create test exec commandline bash c bash c my file dir script sh the problem is that i cannot run this script because i have spaces in my dir name i have tried everything e g commandline bash c bash c my file dir script sh tokenize commandline bash c bash c my file dir script sh commandline bash c new stringbuilder append bash append c my file dir script sh commandline bash c bash c my file dir script sh file dir file c my file dir script sh commandline bash c bash dir getabsolutepath im using windows bit and if i use a path without spaces the script runs perfectly therefore the only issue as i can see is how gradle handles spaces '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPsY-dDF4f3Z"
      },
      "source": [
        "# Creating the IDF\n",
        "\n",
        "CountVectorizer to create a vocabulary and generate word counts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTdK8JQzpRpD"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVcmYww15KBz"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import re\n",
        "import base64\n",
        "import requests\n",
        "\n",
        "def get_stop_words(stop_file_path):\n",
        "    \"\"\"load stop words \"\"\"\n",
        "    stopwords = requests.get(stop_file_path)\n",
        "    #stopwords = f.readlines()\n",
        "    stop_set = set(m.strip() for m in stopwords)\n",
        "    return frozenset(stop_set)\n",
        "\n",
        "#load a set of stop words\n",
        "stopwords=get_stop_words(\"https://raw.githubusercontent.com/huynhhoc/AI-VLU/main/resources/stopwords.txt\")\n",
        "\n",
        "#get the text column \n",
        "docs=df_idf['text'].tolist()\n",
        "\n",
        "#create a vocabulary of words, \n",
        "#ignore words that appear in 85% of documents, \n",
        "#eliminate stop words\n",
        "cv=CountVectorizer(max_df=0.85,stop_words=stopwords)\n",
        "word_count_vector=cv.fit_transform(docs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XV4RcwwN9t7s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31d2fc12-29d8-4e87-e2eb-50abdca48899"
      },
      "source": [
        "\n",
        "word_count_vector.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20000, 125311)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y52tkT4L96cK"
      },
      "source": [
        "Let's limit our vocabulary size to 10,000"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guowMnOk97wc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "539b5b24-cd8c-4f8b-efdd-0de99689b27f"
      },
      "source": [
        "cv=CountVectorizer(max_df=0.85,stop_words=stopwords,max_features=10000)\n",
        "word_count_vector=cv.fit_transform(docs)\n",
        "word_count_vector.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20000, 10000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tISTBy7A-CLS"
      },
      "source": [
        "Now, let's look at 10 words from our vocabulary. Sweet, these are mostly programming related."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFwdsCTn-FXa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7265197f-a1f8-45f6-e1ec-43ec44d5f34f"
      },
      "source": [
        "list(cv.vocabulary_.keys())[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['serializing',\n",
              " 'private',\n",
              " 'struct',\n",
              " 'can',\n",
              " 'it',\n",
              " 'be',\n",
              " 'done',\n",
              " 'have',\n",
              " 'public',\n",
              " 'class']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjXm_7Br-Pja"
      },
      "source": [
        "\n",
        "We can also get the vocabulary by using get_feature_names()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fI7yQnZP-QxG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4db68db-4600-42fd-c4ce-2ef741ff72be"
      },
      "source": [
        "list(cv.get_feature_names())[2000:2015]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['custom_widget',\n",
              " 'customer',\n",
              " 'customer_id',\n",
              " 'customerid',\n",
              " 'customers',\n",
              " 'customization',\n",
              " 'customize',\n",
              " 'customized',\n",
              " 'customview',\n",
              " 'cut',\n",
              " 'cv',\n",
              " 'cv_',\n",
              " 'cval',\n",
              " 'cvc',\n",
              " 'cw']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8Jh4fCR-ZWM"
      },
      "source": [
        "# TfidfTransformer to Compute Inverse Document Frequency (IDF)¶"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFTfzSAp-c5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "278ca2d7-3399-4df2-f558-b98942cfa231"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True)\n",
        "tfidf_transformer.fit(word_count_vector)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvV9JHj0-jlb"
      },
      "source": [
        "\n",
        "Let's look at some of the IDF values:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqCZnATm-kBE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e16d249-fbbc-412c-82f4-3ff85ef1e190"
      },
      "source": [
        "tfidf_transformer.idf_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 7.37717703,  9.80492526,  9.51724319, ...,  8.82409601,\n",
              "       10.21039037,  9.51724319])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7dJvs7q-kXi"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2Zl9J19-rgK"
      },
      "source": [
        "# Computing TF-IDF and Extracting Keywords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVZL2y1v-tLa"
      },
      "source": [
        "# read test docs into a dataframe and concatenate title and body\n",
        "df_test=pd.read_json(\"https://raw.githubusercontent.com/huynhhoc/AI-VLU/main/Data/stackoverflow-test.json\",lines=True)\n",
        "df_test['text'] = df_test['title'] + df_test['body']\n",
        "df_test['text'] =df_test['text'].apply(lambda x:pre_process(x))\n",
        "\n",
        "# get test docs into a list\n",
        "docs_test=df_test['text'].tolist()\n",
        "docs_title=df_test['title'].tolist()\n",
        "docs_body=df_test['body'].tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGF98feE_BJF"
      },
      "source": [
        "def sort_coo(coo_matrix):\n",
        "    tuples = zip(coo_matrix.col, coo_matrix.data)\n",
        "    return sorted(tuples, key=lambda x: (x[1], x[0]), reverse=True)\n",
        "\n",
        "def extract_topn_from_vector(feature_names, sorted_items, topn=10):\n",
        "    \"\"\"get the feature names and tf-idf score of top n items\"\"\"\n",
        "    \n",
        "    #use only topn items from vector\n",
        "    sorted_items = sorted_items[:topn]\n",
        "\n",
        "    score_vals = []\n",
        "    feature_vals = []\n",
        "\n",
        "    for idx, score in sorted_items:\n",
        "        fname = feature_names[idx]\n",
        "        \n",
        "        #keep track of feature name and its corresponding score\n",
        "        score_vals.append(round(score, 3))\n",
        "        feature_vals.append(feature_names[idx])\n",
        "\n",
        "    #create a tuples of feature,score\n",
        "    #results = zip(feature_vals,score_vals)\n",
        "    results= {}\n",
        "    for idx in range(len(feature_vals)):\n",
        "        results[feature_vals[idx]]=score_vals[idx]\n",
        "    \n",
        "    return results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fIIB_Gi_EEK"
      },
      "source": [
        "The next step is to compute the tf-idf value for a given document in our test set by invoking tfidf_transformer.transform(...). This generates a vector of tf-idf scores. Next, we sort the words in the vector in descending order of tf-idf values and then iterate over to extract the top-n items with the corresponding feature names, In the example below, we are extracting keywords for the first document in our test set.\n",
        "\n",
        "The sort_coo(...) method essentially sorts the values in the vector while preserving the column index. Once you have the column index then its really easy to look-up the corresponding word value as you would see in extract_topn_from_vector(...) where we do feature_vals.append(feature_names[idx])."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqCL99de_Eqz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c1eab13-06f1-4c1f-986c-bc813a4477b2"
      },
      "source": [
        "# you only needs to do this once\n",
        "feature_names=cv.get_feature_names()\n",
        "\n",
        "# get the document that we want to extract keywords from\n",
        "doc=docs_test[0]\n",
        "\n",
        "#generate tf-idf for the given document\n",
        "tf_idf_vector=tfidf_transformer.transform(cv.transform([doc]))\n",
        "\n",
        "#sort the tf-idf vectors by descending order of scores\n",
        "sorted_items=sort_coo(tf_idf_vector.tocoo())\n",
        "\n",
        "#extract only the top n; n here is 10\n",
        "keywords=extract_topn_from_vector(feature_names,sorted_items,10)\n",
        "\n",
        "# now print the results\n",
        "print(\"\\n=====Title=====\")\n",
        "print(docs_title[0])\n",
        "print(\"\\n=====Body=====\")\n",
        "print(docs_body[0])\n",
        "print(\"\\n===Keywords===\")\n",
        "for k in keywords:\n",
        "    print(k,keywords[k])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "=====Title=====\n",
            "Integrate War-Plugin for m2eclipse into Eclipse Project\n",
            "\n",
            "=====Body=====\n",
            "<p>I set up a small web project with JSF and Maven. Now I want to deploy on a Tomcat server. Is there a possibility to automate that like a button in Eclipse that automatically deploys the project to Tomcat?</p>\n",
            "\n",
            "<p>I read about a the <a href=\"http://maven.apache.org/plugins/maven-war-plugin/\" rel=\"nofollow noreferrer\">Maven War Plugin</a> but I couldn't find a tutorial how to integrate that into my process (eclipse/m2eclipse).</p>\n",
            "\n",
            "<p>Can you link me to help or try to explain it. Thanks.</p>\n",
            "\n",
            "===Keywords===\n",
            "eclipse 0.574\n",
            "war 0.307\n",
            "integrate 0.272\n",
            "maven 0.264\n",
            "tomcat 0.261\n",
            "project 0.231\n",
            "plugin 0.207\n",
            "automate 0.152\n",
            "jsf 0.147\n",
            "possibility 0.142\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p07AKthn_mRq"
      },
      "source": [
        "From the keywords above, the top keywords actually make sense, it talks about eclipse, maven, integrate, war and tomcat which are all unique to this specific question. There are a couple of kewyords that could have been eliminated such as possibility and perhaps even project and you can do this by adding more common words to your stop list and you can even create your own set of stop list, very specific to your domain as described here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIKfgzTO_m97"
      },
      "source": [
        "# put the common code into several methods\n",
        "def get_keywords(idx):\n",
        "\n",
        "    #generate tf-idf for the given document\n",
        "    tf_idf_vector=tfidf_transformer.transform(cv.transform([docs_test[idx]]))\n",
        "\n",
        "    #sort the tf-idf vectors by descending order of scores\n",
        "    sorted_items=sort_coo(tf_idf_vector.tocoo())\n",
        "\n",
        "    #extract only the top n; n here is 10\n",
        "    keywords=extract_topn_from_vector(feature_names,sorted_items,10)\n",
        "    \n",
        "    return keywords\n",
        "\n",
        "def print_results(idx,keywords):\n",
        "    # now print the results\n",
        "    print(\"\\n=====Title=====\")\n",
        "    print(docs_title[idx])\n",
        "    print(\"\\n=====Body=====\")\n",
        "    print(docs_body[idx])\n",
        "    print(\"\\n===Keywords===\")\n",
        "    for k in keywords:\n",
        "        print(k,keywords[k])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPKH9P6d_rck"
      },
      "source": [
        "Now let's look at keywords generated for a much longer question:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzBdJPwd_sBD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ad98801-09dc-4a0a-cd33-7c10af83d85e"
      },
      "source": [
        "idx=120\n",
        "keywords=get_keywords(idx)\n",
        "print_results(idx,keywords)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "=====Title=====\n",
            "SQL Import Wizard - Error\n",
            "\n",
            "=====Body=====\n",
            "<p>I have a CSV file that I'm trying to import into SQL Management Server Studio.</p>\n",
            "\n",
            "<p>In Excel, the column giving me trouble looks like this:\n",
            "<a href=\"https://i.stack.imgur.com/pm0uS.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/pm0uS.png\" alt=\"enter image description here\"></a></p>\n",
            "\n",
            "<p>Tasks > import data > Flat Source File > select file</p>\n",
            "\n",
            "<p><a href=\"https://i.stack.imgur.com/G4b6I.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/G4b6I.png\" alt=\"enter image description here\"></a></p>\n",
            "\n",
            "<p>I set the data type for this column to DT_NUMERIC, adjust the DataScale to 2 in order to get 2 decimal places, but when I click over to Preview, I see that it's clearly not recognizing the numbers appropriately:</p>\n",
            "\n",
            "<p><a href=\"https://i.stack.imgur.com/NZhiQ.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/NZhiQ.png\" alt=\"enter image description here\"></a></p>\n",
            "\n",
            "<p>The column mapping for this column is set to type = decimal; precision 18; scale 2.</p>\n",
            "\n",
            "<p>Error message: Data Flow Task 1: Data conversion failed. The data conversion for column \"Amount\" returned status value 2 and status text \"The value could not be converted because of a potential loss of data.\".\n",
            " (SQL Server Import and Export Wizard)</p>\n",
            "\n",
            "<p>Can someone identify where I'm going wrong here?  Thanks!</p>\n",
            "\n",
            "===Keywords===\n",
            "column 0.354\n",
            "import 0.278\n",
            "data 0.275\n",
            "wizard 0.261\n",
            "decimal 0.22\n",
            "conversion 0.217\n",
            "sql 0.211\n",
            "status 0.159\n",
            "file 0.143\n",
            "appropriately 0.138\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYWMe1iG_waE"
      },
      "source": [
        "# Generate keywords for a batch of documents"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZVWhJCA_yij",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "60bbe17f-2734-4d3b-b3e0-b19f6bc2faf8"
      },
      "source": [
        "#generate tf-idf for all documents in your list. docs_test has 500 documents\n",
        "tf_idf_vector=tfidf_transformer.transform(cv.transform(docs_test))\n",
        "\n",
        "results=[]\n",
        "for i in range(tf_idf_vector.shape[0]):\n",
        "    \n",
        "    # get vector for a single document\n",
        "    curr_vector=tf_idf_vector[i]\n",
        "    \n",
        "    #sort the tf-idf vector by descending order of scores\n",
        "    sorted_items=sort_coo(curr_vector.tocoo())\n",
        "\n",
        "    #extract only the top n; n here is 10\n",
        "    keywords=extract_topn_from_vector(feature_names,sorted_items,10)\n",
        "    \n",
        "    \n",
        "    results.append(keywords)\n",
        "\n",
        "df=pd.DataFrame(zip(docs,results),columns=['doc','keywords'])\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>doc</th>\n",
              "      <th>keywords</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>serializing a private struct can it be done i ...</td>\n",
              "      <td>{'eclipse': 0.574, 'war': 0.307, 'integrate': ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>how do i prevent floated right content from ov...</td>\n",
              "      <td>{'evaluate': 0.448, 'content': 0.382, 'console...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>gradle command line i m trying to run a shell ...</td>\n",
              "      <td>{'appdomain': 0.354, 'dynamic': 0.332, 'vs': 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>loop variable as parameter in asynchronous fun...</td>\n",
              "      <td>{'image': 0.415, 'jpg': 0.404, 'background': 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>canot get the href value hi i need to valid th...</td>\n",
              "      <td>{'uri': 0.366, 'bitmap': 0.314, 'intent': 0.30...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>how to unbind click and click submit button in...</td>\n",
              "      <td>{'delphi': 0.578, 'compatible': 0.341, 'win': ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>swaggerui auth redirect swaggeruiauth of null ...</td>\n",
              "      <td>{'node': 0.514, 'selectsinglenode': 0.285, 'nu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>ssrs value display error for ssrs conditional ...</td>\n",
              "      <td>{'logo': 0.499, 'step': 0.3, 'triangle': 0.296...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>accessing and changing a class instance from a...</td>\n",
              "      <td>{'length': 0.39, 'ev': 0.379, 'introduce': 0.3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>how to print the current time in the format da...</td>\n",
              "      <td>{'oauth': 0.373, 'localhost': 0.368, 'sdk': 0....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   doc                                           keywords\n",
              "0    serializing a private struct can it be done i ...  {'eclipse': 0.574, 'war': 0.307, 'integrate': ...\n",
              "1    how do i prevent floated right content from ov...  {'evaluate': 0.448, 'content': 0.382, 'console...\n",
              "2    gradle command line i m trying to run a shell ...  {'appdomain': 0.354, 'dynamic': 0.332, 'vs': 0...\n",
              "3    loop variable as parameter in asynchronous fun...  {'image': 0.415, 'jpg': 0.404, 'background': 0...\n",
              "4    canot get the href value hi i need to valid th...  {'uri': 0.366, 'bitmap': 0.314, 'intent': 0.30...\n",
              "..                                                 ...                                                ...\n",
              "495  how to unbind click and click submit button in...  {'delphi': 0.578, 'compatible': 0.341, 'win': ...\n",
              "496  swaggerui auth redirect swaggeruiauth of null ...  {'node': 0.514, 'selectsinglenode': 0.285, 'nu...\n",
              "497  ssrs value display error for ssrs conditional ...  {'logo': 0.499, 'step': 0.3, 'triangle': 0.296...\n",
              "498  accessing and changing a class instance from a...  {'length': 0.39, 'ev': 0.379, 'introduce': 0.3...\n",
              "499  how to print the current time in the format da...  {'oauth': 0.373, 'localhost': 0.368, 'sdk': 0....\n",
              "\n",
              "[500 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    }
  ]
}